<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Martin Wright - Research</title>
    <link rel="stylesheet" href="css/style.css">
</head>
<body>
    <header>
        <h1>Martin Wright &mu;</h1>
        <nav>
            <a href="#" class="active">Home</a>
            <a href="#">Research</a>
            <a href="#">Publications</a>
            <a href="#">About</a>
        </nav>
    </header>

    <main>
        <div class="intro">
            <p>I am a researcher and engineer focused on the fields of machine learning, simulation and operations research. My work spans computer vision, data science, and their applications to real-world problems in scheduling, hydrology and engineering. </p>
        </div>

        <section class="research-section">
            <!-- <h2 class="research-heading">Recent Research</h2> -->

            <div class="research-item">
                <div class="research-title">LSTM </div>
                <div class="research-date">June 3, 2024</div>
                <div class="research-description">
                    We introduce a sparse attention mechanism that scales linearly with sequence length while maintaining model quality. Our method enables processing of documents up to 100k tokens with minimal computational overhead.
                </div>
            </div>

            <div class="research-item">
                <div class="research-title">Intelligent Semantic Caching for Video Surveillance Systems</div>
                <div class="research-date">February 2025</div>
                <div class="research-description">
                    A novel approach to the task of 
                </div>
            </div>

            <div class="research-item">
                <div class="paper-box">
                    <div class="research-title">Self-Supervised Representation Learning from Temporal Dynamics</div>
                    <div class="research-date">March 12, 2024</div>
                    <div class="research-description">
                        Our latest work on learning robust representations from video data without manual annotations. By leveraging temporal consistency and cross-frame prediction, we achieve representations that transfer exceptionally well to downstream tasks, outperforming supervised pre-training on several benchmarks.
                    </div>
                </div>
            </div>

            <div class="research-item">
                <div class="research-title">Uncertainty Quantification in Deep Neural Networks</div>
                <div class="research-date">January 28, 2024</div>
                <div class="research-description">
                    A framework for reliable uncertainty estimation in deep learning models that enables safe deployment in high-stakes applications. We demonstrate improved calibration and out-of-distribution detection across medical imaging and autonomous systems.
                </div>
            </div>

            <div class="research-item">
                <div class="paper-box">
                    <div class="research-title">Meta-Learning for Few-Shot Domain Adaptation</div>
                    <div class="research-date">November 5, 2023</div>
                    <div class="research-description">
                        We present a meta-learning approach that enables rapid adaptation to new domains with only a handful of examples. Our method combines gradient-based meta-learning with domain-invariant feature extraction, achieving significant improvements over traditional transfer learning approaches in low-data regimes.
                    </div>
                </div>
            </div>

            <div class="research-item">
                <div class="research-title">Interpretable Deep Learning through Concept Bottlenecks</div>
                <div class="research-date">September 18, 2023</div>
                <div class="research-description">
                    An architecture that forces model predictions to go through human-interpretable concepts, making deep learning models transparent and debuggable while maintaining competitive accuracy on complex tasks.
                </div>
            </div>
        </section>
    </main>

    <footer>
        <p>Â© 2025 Martin Wright. All rights reserved.</p>
    </footer>
</body>
</html>